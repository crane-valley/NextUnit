name: Speed Comparison Benchmarks

on:
  workflow_dispatch:
    inputs:
      iterations:
        description: 'Number of iterations per framework (default: 5)'
        required: false
        default: '5'
  schedule:
    # Run every Sunday at midnight UTC
    - cron: '0 0 * * 0'
  pull_request:
    paths:
      - 'src/**'
      - 'tools/speed-comparison/**'
      - '.github/workflows/speed-comparison.yml'

permissions:
  contents: write  # Required to commit results back to repository
  pull-requests: write  # Required to comment on pull requests

env:
  DOTNET_VERSION: '10.0.x'
  DOTNET_NOLOGO: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true

jobs:
  benchmark:
    name: Run Speed Comparison
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          fetch-depth: 0
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v5
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
      
      - name: Display .NET info
        run: dotnet --info
      
      - name: Restore dependencies
        run: dotnet restore
      
      - name: Build speed comparison projects
        run: |
          echo "Building speed comparison projects..."
          cd tools/speed-comparison
          dotnet build Tests.Benchmark/Tests.Benchmark.csproj --configuration Release --no-restore
      
      - name: Run speed comparison benchmarks
        run: |
          echo "=== Running Speed Comparison Benchmarks with BenchmarkDotNet ==="
          cd tools/speed-comparison/Tests.Benchmark
          dotnet run -c Release --no-build
        continue-on-error: false
      
      - name: Display benchmark results
        run: |
          echo "=== Benchmark Results ==="
          # BenchmarkDotNet outputs to BenchmarkDotNet.Artifacts/results/
          LATEST_RESULT=$(find tools/speed-comparison/Tests.Benchmark/BenchmarkDotNet.Artifacts/results -name "*.md" -type f 2>/dev/null | head -1)
          if [ -n "$LATEST_RESULT" ] && [ -f "$LATEST_RESULT" ]; then
            cat "$LATEST_RESULT"
          else
            echo "No benchmark results found"
            ls -R tools/speed-comparison/Tests.Benchmark/BenchmarkDotNet.Artifacts/ || echo "BenchmarkDotNet.Artifacts directory not found"
          fi
        if: always()
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v5
        with:
          name: speed-comparison-results
          path: |
            tools/speed-comparison/Tests.Benchmark/BenchmarkDotNet.Artifacts/results/*.md
            tools/speed-comparison/Tests.Benchmark/BenchmarkDotNet.Artifacts/results/*.html
          retention-days: 90
        if: always()
      
      - name: Comment PR with results (on pull requests)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Find the latest benchmark result markdown file
            const artifactsDir = 'tools/speed-comparison/Tests.Benchmark/BenchmarkDotNet.Artifacts/results';
            
            if (!fs.existsSync(artifactsDir)) {
              console.log('BenchmarkDotNet artifacts directory not found');
              return;
            }
            
            const mdFiles = fs.readdirSync(artifactsDir)
              .filter(f => f.endsWith('.md'))
              .map(f => ({
                name: f,
                path: path.join(artifactsDir, f),
                mtime: fs.statSync(path.join(artifactsDir, f)).mtime
              }))
              .sort((a, b) => b.mtime - a.mtime);
            
            if (mdFiles.length === 0) {
              console.log('No benchmark result files found');
              return;
            }
            
            const results = fs.readFileSync(mdFiles[0].path, 'utf8');
            
            // BenchmarkDotNet generates comprehensive markdown - use it as-is
            const comment = `## ðŸš€ Speed Comparison Results (BenchmarkDotNet)\n\n${results}\n\n---\n*Benchmarks run on ${new Date().toISOString()}*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
        continue-on-error: true

  summary:
    name: Benchmark Summary
    runs-on: ubuntu-latest
    needs: benchmark
    if: always()
    
    steps:
      - name: Download results
        uses: actions/download-artifact@v5
        with:
          name: speed-comparison-results
          path: results
        continue-on-error: true
      
      - name: Generate job summary
        run: |
          echo "# Speed Comparison Benchmark Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Find the latest markdown file from BenchmarkDotNet results
          LATEST_MD=$(find results -name "*.md" -type f 2>/dev/null | head -1)
          
          if [ -n "$LATEST_MD" ] && [ -f "$LATEST_MD" ]; then
            cat "$LATEST_MD" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âœ… Benchmarks completed successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Benchmark results not found" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Available files:" >> $GITHUB_STEP_SUMMARY
            find results -type f 2>/dev/null || echo "No files found" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Job Status**: ${{ needs.benchmark.result }}" >> $GITHUB_STEP_SUMMARY
        continue-on-error: true
